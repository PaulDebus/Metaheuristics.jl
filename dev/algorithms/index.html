<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Algorithms · Metaheuristics.jl</title><script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-184071594-1', 'auto');
ga('send', 'pageview', {'page': location.pathname + location.search + location.hash});
</script><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.0/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script><link href="../assets/favicon.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../"><img src="../assets/logo.png" alt="Metaheuristics.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit">Metaheuristics.jl</span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Index</a></li><li><a class="tocitem" href="../tutorial/">Tutorial</a></li><li><a class="tocitem" href="../examples/">Examples</a></li><li class="is-active"><a class="tocitem" href>Algorithms</a><ul class="internal"><li><a class="tocitem" href="#Evolutionary-Centers-Algorithm"><span>Evolutionary Centers Algorithm</span></a></li><li><a class="tocitem" href="#Differential-Evolution"><span>Differential Evolution</span></a></li><li><a class="tocitem" href="#Particle-Swarm-Optimization"><span>Particle Swarm Optimization</span></a></li><li><a class="tocitem" href="#Artificial-Bee-Colony"><span>Artificial Bee Colony</span></a></li><li><a class="tocitem" href="#MOEA/D-DE"><span>MOEA/D-DE</span></a></li><li><a class="tocitem" href="#Gravitational-Search-Algorithm"><span>Gravitational Search Algorithm</span></a></li><li><a class="tocitem" href="#Simulated-Annealing"><span>Simulated Annealing</span></a></li><li><a class="tocitem" href="#Whale-Optimization-Algorithm"><span>Whale Optimization Algorithm</span></a></li><li><a class="tocitem" href="#NSGA-II"><span>NSGA-II</span></a></li><li><a class="tocitem" href="#NSGA-III"><span>NSGA-III</span></a></li></ul></li><li><a class="tocitem" href="../problems/">Problems</a></li><li><a class="tocitem" href="../indicators/">Performance Indicators</a></li><li><a class="tocitem" href="../visualization/">Visualization</a></li><li><a class="tocitem" href="../api/">API References</a></li><li><a class="tocitem" href="../contributing/">Contributing</a></li><li><a class="tocitem" href="../references/">References</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Algorithms</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Algorithms</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/jmejia8/Metaheuristics.jl/blob/master/docs/src/algorithms.md" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Algorithms"><a class="docs-heading-anchor" href="#Algorithms">Algorithms</a><a id="Algorithms-1"></a><a class="docs-heading-anchor-permalink" href="#Algorithms" title="Permalink"></a></h1><p>List of implemented metaheuristics.</p><h2 id="Evolutionary-Centers-Algorithm"><a class="docs-heading-anchor" href="#Evolutionary-Centers-Algorithm">Evolutionary Centers Algorithm</a><a id="Evolutionary-Centers-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Evolutionary-Centers-Algorithm" title="Permalink"></a></h2><p>ECA was proposed for solving global optimization problems. See <a href="../references/#MejiaMezura2019">J.-A. Mejía-de-Dios, E. Mezura-Montes (2019)</a> for more information.</p><article class="docstring"><header><a class="docstring-binding" id="Metaheuristics.ECA" href="#Metaheuristics.ECA"><code>Metaheuristics.ECA</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ECA(;
    η_max = 2.0,
    K = 7,
    N = 0,
    N_init = N,
    p_exploit = 0.95,
    p_bin = 0.02,
    p_cr = Float64[],
    adaptive = false,
    resize_population = false,
    information = Information(),
    options = Options()
)</code></pre><p>Parameters for the metaheuristic ECA: step-size <code>η_max</code>,<code>K</code> is number of vectors to generate the center of mass, <code>N</code> is the population size.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; f(x) = sum(x.^2)
f (generic function with 1 method)

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], ECA())
+=========== RESULT ==========+
  iteration: 1429
    minimum: 3.3152400000000004e-223
  minimizer: [4.213750597785841e-113, 5.290977430907081e-112, 2.231685329262638e-112]
    f calls: 29989
 total time: 0.1672 s
+============================+

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], ECA(N = 10, η_max = 1.0, K = 3))
+=========== RESULT ==========+
  iteration: 3000
    minimum: 0.000571319
  minimizer: [-0.00017150889316537758, -0.007955828028420616, 0.022538733289139145]
    f calls: 30000
 total time: 0.1334 s
+============================+</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmejia8/Metaheuristics.jl/blob/0226894f1d14d815e4ad6249475b18d9b45ea757/src/algorithms/ECA/ECA.jl#L18-L61">source</a></section></article><h2 id="Differential-Evolution"><a class="docs-heading-anchor" href="#Differential-Evolution">Differential Evolution</a><a id="Differential-Evolution-1"></a><a class="docs-heading-anchor-permalink" href="#Differential-Evolution" title="Permalink"></a></h2><p>DE is an evolutionary algorithm based on vector differences. See <a href="../references/#Price2013">K. V. Price (2013)</a> for more details.</p><article class="docstring"><header><a class="docstring-binding" id="Metaheuristics.DE" href="#Metaheuristics.DE"><code>Metaheuristics.DE</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">DE(;
    N  = 0,
    F  = 1.0,
    CR = 0.9,
    strategy = :rand1,
    information = Information(),
    options = Options()
)</code></pre><p>Parameters for Differential Evolution (DE) algorithm: step-size <code>F</code>,<code>CR</code> controlls the binomial crossover, <code>N</code> is the population size. The parameter <code>trategy</code> is related to the variation operator (<code>:rand1</code>, <code>:rand2</code>, <code>:best1</code>, <code>:best2</code>, <code>:randToBest1</code>).</p><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; f(x) = sum(x.^2)
f (generic function with 1 method)

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], DE())
+=========== RESULT ==========+
  iteration: 1000
    minimum: 0
  minimizer: [0.0, 0.0, 0.0]
    f calls: 30000
 total time: 0.0437 s
+============================+

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], DE(N=50, F=1.5, CR=0.8))
+=========== RESULT ==========+
  iteration: 600
    minimum: 8.68798e-25
  minimizer: [3.2777877981303293e-13, 3.7650459509488005e-13, -7.871487597385812e-13]
    f calls: 30000
 total time: 0.0319 s
+============================+</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmejia8/Metaheuristics.jl/blob/0226894f1d14d815e4ad6249475b18d9b45ea757/src/algorithms/DE/DE.jl#L14-L53">source</a></section></article><h2 id="Particle-Swarm-Optimization"><a class="docs-heading-anchor" href="#Particle-Swarm-Optimization">Particle Swarm Optimization</a><a id="Particle-Swarm-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Particle-Swarm-Optimization" title="Permalink"></a></h2><p>PSO is a population-based optimization technique inspired by the motion of bird flocks and schooling fish (<a href="../references/#KennedyEberhart1995">J. Kennedy, R. Eberhart (1995)</a>).</p><article class="docstring"><header><a class="docstring-binding" id="Metaheuristics.PSO" href="#Metaheuristics.PSO"><code>Metaheuristics.PSO</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">PSO(;
    N  = 0,
    C1 = 2.0,
    C2 = 2.0,
    ω  = 0.8,
    information = Information(),
    options = Options()
)</code></pre><p>Parameters for Particle Swarm Optimization (PSO) algorithm: learning rates <code>C1</code> and <code>C2</code>, <code>N</code> is the population size and <code>ω</code> controlls the inertia weight. </p><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; f(x) = sum(x.^2)
f (generic function with 1 method)

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], PSO())
+=========== RESULT ==========+
  iteration: 1000
    minimum: 1.40522e-49
  minimizer: [3.0325415595139883e-25, 1.9862212295897505e-25, 9.543772256546461e-26]
    f calls: 30000
 total time: 0.1558 s
+============================+

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], PSO(N = 100, C1=1.5, C2=1.5, ω = 0.7))
+=========== RESULT ==========+
  iteration: 300
    minimum: 2.46164e-39
  minimizer: [-3.055334698085433e-20, -8.666986835846171e-21, -3.8118413472544027e-20]
    f calls: 30000
 total time: 0.1365 s
+============================+</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmejia8/Metaheuristics.jl/blob/0226894f1d14d815e4ad6249475b18d9b45ea757/src/algorithms/PSO/PSO.jl#L14-L51">source</a></section></article><h2 id="Artificial-Bee-Colony"><a class="docs-heading-anchor" href="#Artificial-Bee-Colony">Artificial Bee Colony</a><a id="Artificial-Bee-Colony-1"></a><a class="docs-heading-anchor-permalink" href="#Artificial-Bee-Colony" title="Permalink"></a></h2><p>A powerful and efficient algorithm for numerical function optimization: artificial bee colony (ABC) algorithm by <a href="../references/#KarabogaBasturk2007">D. Karaboga, B. Basturk (2007)</a>.</p><article class="docstring"><header><a class="docstring-binding" id="Metaheuristics.ABC" href="#Metaheuristics.ABC"><code>Metaheuristics.ABC</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">ABC(;
    N = 50,
    Ne = div(N+1, 2),
    No = div(N+1, 2),
    limit=10,
    information = Information(),
    options = Options()
)</code></pre><p>ABC implements the original parameters for the Artificial Bee Colony Algorithm. <code>N</code> is the population size, <code>Ne</code> is the number of employees, <code>No</code> is the number of outlookers bees. <code>limit</code> is related to the times that a solution is visited.</p><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; f(x) = sum(x.^2)
f (generic function with 1 method)

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], ABC())
+=========== RESULT ==========+
  iteration: 595
    minimum: 4.03152e-28
  minimizer: [1.489845115451046e-14, 1.2207275971717747e-14, -5.671872444705246e-15]
    f calls: 30020
 total time: 0.0360 s
+============================+

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], ABC(N = 80,  No = 20, Ne = 50, limit=5))
+=========== RESULT ==========+
  iteration: 407
    minimum: 8.94719e-08
  minimizer: [8.257485723496422e-5, 0.0002852795196258074, -3.5620824723352315e-5]
    f calls: 30039
 total time: 0.0432 s
+============================+</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmejia8/Metaheuristics.jl/blob/0226894f1d14d815e4ad6249475b18d9b45ea757/src/algorithms/ABC/ABC.jl#L10-L51">source</a></section></article><h2 id="MOEA/D-DE"><a class="docs-heading-anchor" href="#MOEA/D-DE">MOEA/D-DE</a><a id="MOEA/D-DE-1"></a><a class="docs-heading-anchor-permalink" href="#MOEA/D-DE" title="Permalink"></a></h2><p>Multiobjective optimization problems with complicated Pareto sets by <a href="../references/#LiZhang2008">H. Li, Q. Zhang (2008)</a>.</p><article class="docstring"><header><a class="docstring-binding" id="Metaheuristics.MOEAD_DE" href="#Metaheuristics.MOEAD_DE"><code>Metaheuristics.MOEAD_DE</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">MOEAD_DE(weights)</code></pre><p><code>MOEAD_DE</code> implements the original version of MOEA/D-DE. It uses the contraint handling method based on the sum of violations (for constrained optimizaton): <code>g(x, λ, z) = max(λ .* abs.(fx - z)) + sum(max.(0, gx)) + sum(abs.(hx))</code></p><p>To use MOEAD_DE, the output from the objective function should be a 3-touple <code>(f::Vector, g::Vector, h::Vector)</code>, where <code>f</code> contains the objective functions, <code>g</code> and <code>h</code> are the equality and inequality constraints respectively.</p><p>A feasible solution is such that <code>g_i(x) ≤ 0 and h_j(x) = 0</code>.</p><p>Ref. Multiobjective Optimization Problems With Complicated Pareto Sets, MOEA/D and NSGA-II; Hui Li and Qingfu Zhang.</p><p><strong>Example</strong></p><p>Assume you want to solve the following optimizaton problem:</p><p>Minimize:</p><p><code>f(x) = (x_1, x_2)</code></p><p>subject to:</p><p><code>g(x) = x_1^2 + x_2^2 - 1 ≤ 0</code></p><p><code>x_1, x_2 ∈ [-1, 1]</code></p><p>A solution can be:</p><pre><code class="language-julia">
# Dimension
D = 2

# Objective function
f(x) = ( x, [sum(x.^2) - 1], [0.0] )

# bounds
bounds = [-1 -1;
           1  1.0
        ]

nobjectives = 2
npartitions = 100

# reference points (Das and Dennis&#39;s method)
weights = gen_ref_dirs(nobjectives, npartitions)

# define the parameters
moead_de = MOEAD_DE(weights, options=Options(debug=false, iterations = 250))

# optimize
status_moead = optimize(f, bounds, moead_de)

# show results
display(status_moead)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmejia8/Metaheuristics.jl/blob/0226894f1d14d815e4ad6249475b18d9b45ea757/src/algorithms/MOEAD_DE/MOEAD_DE.jl#L21-L82">source</a></section></article><h2 id="Gravitational-Search-Algorithm"><a class="docs-heading-anchor" href="#Gravitational-Search-Algorithm">Gravitational Search Algorithm</a><a id="Gravitational-Search-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Gravitational-Search-Algorithm" title="Permalink"></a></h2><p>Chaotic gravitational constants for the gravitational search algorithm by <a href="../references/#MirjaliliGandomi2017">S. Mirjalili, A. H. Gandomi (2017)</a></p><article class="docstring"><header><a class="docstring-binding" id="Metaheuristics.CGSA" href="#Metaheuristics.CGSA"><code>Metaheuristics.CGSA</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">CGSA(;
    N::Int    = 30,
    chValueInitial::Real   = 20,
    chaosIndex::Real   = 9,
    ElitistCheck::Int    = 1,
    Rpower::Int    = 1,
    Rnorm::Int    = 2,
    wMax::Real   = chValueInitial,
    wMin::Real   = 1e-10,
    information = Information(),
    options = Options()
)</code></pre><p>CGSA is an extension of the GSA algorithm but with Chaotic gravitational constants for the gravitational search algorithm.</p><p>Ref. Chaotic gravitational constants for the gravitational search algorithm. Applied Soft Computing 53 (2017): 407-419.</p><p>Parameters:</p><ul><li>N: Population size</li><li>chValueInitial: Initial value for the chaos value</li><li>chaosIndex: Integer 1 ≤ chaosIndex ≤ 10 is the function that model the chaos</li><li>Rpower: power related to the distance norm(x)^Rpower</li><li>Rnorm: is the value as in norm(x, Rnorm)</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; f(x) = sum(x.^2)
f (generic function with 1 method)

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], CGSA())
+=========== RESULT ==========+
  iteration: 500
    minimum: 8.63808e-08
  minimizer: [0.0002658098418993323, -1.140808975532608e-5, -0.00012488307670533095]
    f calls: 15000
 total time: 0.1556 s
+============================+

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], CGSA(N = 80, chaosIndex = 1))
+=========== RESULT ==========+
  iteration: 500
    minimum: 1.0153e-09
  minimizer: [-8.8507563788141e-6, -1.3050111801923072e-5, 2.7688577445980026e-5]
    f calls: 40000
 total time: 1.0323 s
+============================+</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmejia8/Metaheuristics.jl/blob/0226894f1d14d815e4ad6249475b18d9b45ea757/src/algorithms/CGSA/CGSA.jl#L32-L89">source</a></section></article><h2 id="Simulated-Annealing"><a class="docs-heading-anchor" href="#Simulated-Annealing">Simulated Annealing</a><a id="Simulated-Annealing-1"></a><a class="docs-heading-anchor-permalink" href="#Simulated-Annealing" title="Permalink"></a></h2><p>Physics inspired algorithm for optimization <a href="../references/#Van1987">Peter J.M. Van L., E.H.L. Aarts (1987)</a>.</p><article class="docstring"><header><a class="docstring-binding" id="Metaheuristics.SA" href="#Metaheuristics.SA"><code>Metaheuristics.SA</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">    SA(;
        x_initial::Vector = zeros(0),
        N::Int = 500,
        tol_fun::Real= 1e-4,
        information = Information(),
        options = Options()
    )</code></pre><p>Parameters for the method of Simulated Annealing (Kirkpatrick et al., 1983).</p><p>Parameters:</p><ul><li>x_intial: Inital solution. If empty, then SA will generate a random one within the bounds.</li><li>N: The number of test points per iteration.</li><li>tol_fun: tolerance value for the Metropolis condition to accept or reject the test point as current point.</li></ul><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; f(x) = sum(x.^2)
f (generic function with 1 method)

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], SA())
+=========== RESULT ==========+
  iteration: 60
    minimum: 5.0787e-68
  minimizer: [-2.2522059499734615e-34, 3.816133503985569e-36, 6.934348004465088e-36]
    f calls: 29002
 total time: 0.0943 s
+============================+

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], SA(N = 100, x_initial = [1, 0.5, -1]))
+=========== RESULT ==========+
  iteration: 300
    minimum: 1.99651e-69
  minimizer: [4.4638292404181215e-35, -1.738939846089388e-36, -9.542441152683457e-37]
    f calls: 29802
 total time: 0.0965 s
+============================+</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmejia8/Metaheuristics.jl/blob/0226894f1d14d815e4ad6249475b18d9b45ea757/src/algorithms/SA/SA.jl#L15-L63">source</a></section></article><h2 id="Whale-Optimization-Algorithm"><a class="docs-heading-anchor" href="#Whale-Optimization-Algorithm">Whale Optimization Algorithm</a><a id="Whale-Optimization-Algorithm-1"></a><a class="docs-heading-anchor-permalink" href="#Whale-Optimization-Algorithm" title="Permalink"></a></h2><p>The Whale Optimization Algorithm inspired by humpback whales <a href="../references/#MirjaliliLewis2016">S. Mirjalili, A. Lewis (2016)</a>.</p><article class="docstring"><header><a class="docstring-binding" id="Metaheuristics.WOA" href="#Metaheuristics.WOA"><code>Metaheuristics.WOA</code></a> — <span class="docstring-category">Type</span></header><section><div><p>WOA(;N = 30, information = Information(), options = Options())</p><p>Parameters for the Whale Optimization Algorithm. <code>N</code> is the population size (number of whales).</p><p><strong>Example</strong></p><pre><code class="language-julia-repl">julia&gt; f(x) = sum(x.^2)
f (generic function with 1 method)

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], WOA())
+=========== RESULT ==========+
  iteration: 500
    minimum: 3.9154600000000003e-100
  minimizer: [8.96670478694908e-52, -1.9291317455298046e-50, 4.3113080446722046e-51]
    f calls: 15000
 total time: 0.0134 s
+============================+

julia&gt; optimize(f, [-1 -1 -1; 1 1 1.0], WOA(N = 100))
+=========== RESULT ==========+
  iteration: 500
    minimum: 1.41908e-145
  minimizer: [9.236161414012512e-74, -3.634919950380001e-73, 3.536831799149254e-74]
    f calls: 50000
 total time: 0.0588 s
+============================+
</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmejia8/Metaheuristics.jl/blob/0226894f1d14d815e4ad6249475b18d9b45ea757/src/algorithms/WOA/WOA.jl#L20-L53">source</a></section></article><h2 id="NSGA-II"><a class="docs-heading-anchor" href="#NSGA-II">NSGA-II</a><a id="NSGA-II-1"></a><a class="docs-heading-anchor-permalink" href="#NSGA-II" title="Permalink"></a></h2><p>A fast and elitist multiobjective genetic algorithm: NSGA-II<a href="../references/#Deb2002">K. Deb, A. Pratap, S. Agarwal, T. Meyarivan (2002)</a>.</p><article class="docstring"><header><a class="docstring-binding" id="Metaheuristics.NSGA2" href="#Metaheuristics.NSGA2"><code>Metaheuristics.NSGA2</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">function NSGA2(;
    N = 100,
    η_cr = 20,
    p_cr = 0.9,
    η_m = 20,
    p_m = 1.0 / D,
    ε = eps(),
    information = Information(),
    options = Options(),
)</code></pre><p>Parameters for the metaheuristic NSGA-II.</p><p>Parameters:</p><ul><li><code>N</code> Population size.</li><li><code>η_cr</code>  η for the crossover.</li><li><code>p_cr</code> Crossover probability.</li><li><code>η_m</code>  η for the mutation operator.</li><li><code>p_m</code> Mutation probability (1/D for D-dimensional problem by default).</li></ul><p>To use NSGA2, the output from the objective function should be a 3-touple <code>(f::Vector, g::Vector, h::Vector)</code>, where <code>f</code> contains the objective functions, <code>g</code> and <code>h</code> are inequality, equality constraints respectively.</p><p>A feasible solution is such that <code>g_i(x) ≤ 0 and h_j(x) = 0</code>.</p><pre><code class="language-julia">using Metaheuristics

# Dimension
D = 2

# Objective function
f(x) = ( x, [sum(x.^2) - 1], [0.0] ) 

# bounds
bounds = [-1 -1;
           1  1.0
        ]

# define the parameters (use `NSGA2()` for using default parameters)
nsga2 = NSGA2(N = 100, p_cr = 0.85)

# optimize
status = optimize(f, bounds, nsga2)

# show results
display(status)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmejia8/Metaheuristics.jl/blob/0226894f1d14d815e4ad6249475b18d9b45ea757/src/algorithms/NSGA2/NSGA2.jl#L13-L66">source</a></section></article><h2 id="NSGA-III"><a class="docs-heading-anchor" href="#NSGA-III">NSGA-III</a><a id="NSGA-III-1"></a><a class="docs-heading-anchor-permalink" href="#NSGA-III" title="Permalink"></a></h2><p>An Evolutionary Many-Objective Optimization Algorithm Using Reference-Point-Based Nondominated Sorting Approach, Part I: Solving Problems With Box Constraints <a href="../references/#DebJain2014">K. Deb, H. Jain (2014)</a>.</p><article class="docstring"><header><a class="docstring-binding" id="Metaheuristics.NSGA3" href="#Metaheuristics.NSGA3"><code>Metaheuristics.NSGA3</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia">function NSGA3(;
    N = 100,
    η_cr = 20,
    p_cr = 0.9,
    η_m = 20,
    p_m = 1.0 / D,
    ε = eps(),
    information = Information(),
    options = Options(),
)</code></pre><p>Parameters for the metaheuristic NSGA-III.</p><p>Parameters:</p><ul><li><code>N</code> Population size.</li><li><code>η_cr</code>  η for the crossover.</li><li><code>p_cr</code> Crossover probability.</li><li><code>η_m</code>  η for the mutation operator.</li><li><code>p_m</code> Mutation probability (1/D for D-dimensional problem by default).</li></ul><p>To use NSGA3, the output from the objective function should be a 3-touple <code>(f::Vector, g::Vector, h::Vector)</code>, where <code>f</code> contains the objective functions, <code>g</code> and <code>h</code> are inequality, equality constraints respectively.</p><p>A feasible solution is such that <code>g_i(x) ≤ 0 and h_j(x) = 0</code>.</p><pre><code class="language-julia">using Metaheuristics


# Objective function, bounds, and the True Pareto front
f, bounds, pf = Metaheuristics.TestProblems.get_problem(:DTLZ2)


# define the parameters (use `NSGA3()` for using default parameters)
nsga3 = NSGA3(p_cr = 0.9)

# optimize
status = optimize(f, bounds, nsga3)

# show results
display(status)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/jmejia8/Metaheuristics.jl/blob/0226894f1d14d815e4ad6249475b18d9b45ea757/src/algorithms/NSGA3/NSGA3.jl#L13-L60">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../examples/">« Examples</a><a class="docs-footer-nextpage" href="../problems/">Problems »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> on <span class="colophon-date" title="Wednesday 1 September 2021 04:27">Wednesday 1 September 2021</span>. Using Julia version 1.4.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
